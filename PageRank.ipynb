{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Graph\n",
    "Name: Phillis Ye  \n",
    "StudentID: 452535825  \n",
    "UPI: zye615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Implement the power iteration in matrix form without considering the dead-ends and spider traps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data in.\n",
    "web_data = pd.read_csv(\"web-Google.txt\", sep=\" \", header=None, names=['from', 'to'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[     0      1]\n",
      " [     0      2]\n",
      " [     0      3]\n",
      " ...\n",
      " [875712  13656]\n",
      " [875712   9430]\n",
      " [875712 542451]]\n"
     ]
    }
   ],
   "source": [
    "# convert data into numpy array format\n",
    "web_array = web_data.to_numpy()\n",
    "print(web_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5105039, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# size of the data\n",
    "web_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of outlinks for each node.\n",
    "unique, counts = np.unique(web_array[:,0], return_counts=True)\n",
    "outlinks = dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the rank score for all the nodes and report:\n",
    "\n",
    "#### (a) The running time and the number of iterations needed to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function to create the sparse adjacency matrix M.\n",
    "def adjacency_matrix(links, outlinks, n):\n",
    "    # create empty row, col, and value to store the values\n",
    "    row = list()\n",
    "    col = list()\n",
    "    value = list()\n",
    "    \n",
    "    # number of lines in the file.\n",
    "    nrow = len(links)\n",
    "    # iterate each line in the file to store the directed edge from one node to the other.\n",
    "    for i in range(nrow):\n",
    "        # get the from node number and to node number\n",
    "        from_node = links[i,0]\n",
    "        to_node = links[i,1]\n",
    "        \n",
    "        # find the number of outlinks for the from node.\n",
    "        out = outlinks[from_node]\n",
    "        \n",
    "        # append the value into the row, col, and value, such that value Mji = 1/di\n",
    "        row.append(to_node)\n",
    "        col.append(from_node)\n",
    "        value.append(1/out)\n",
    "    \n",
    "    # convert the row, col, and value into numpy array\n",
    "    row = np.array(row)\n",
    "    col = np.array(col)\n",
    "    value = np.array(value)\n",
    "    \n",
    "    # construct the compressed sparse row matrix using csr_matrix((data, (row, col)), shape)\n",
    "    # the matrix is NxN where N is number of nodes in the file.\n",
    "    matrix = csr_matrix((value, (row, col)), shape = (n,n))\n",
    "    \n",
    "    return matrix\n",
    "\n",
    "# implement the power iteration in matrix form without considering the dead-ends and spider traps.\n",
    "def power_iteration(M, r, threshold):\n",
    "    # initialise the iteration number to be zero.\n",
    "    iteration = 0\n",
    "    \n",
    "    # initialise the difference between new_r and old_r to be infinite.\n",
    "    difference = float(\"inf\")\n",
    "    # initialise the old_r.\n",
    "    old_r = r\n",
    "    \n",
    "    # the iteration stops while difference < threshold.\n",
    "    while difference >= threshold:\n",
    "        # number of iteration adds 1.\n",
    "        iteration += 1\n",
    "        \n",
    "        # new_r equals the matrix M dot product the old_r\n",
    "        new_r = M.dot(old_r)\n",
    "        # the difference is the sum of the absolute values of the difference between new_r and old_r.\n",
    "        difference = np.sum(np.abs(np.subtract(new_r, old_r)))\n",
    "        # the new_r becomes old_r for next iteration.\n",
    "        old_r = new_r\n",
    "    \n",
    "    # return the final number of iterations and final rank score.\n",
    "    return iteration, old_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sparse matrix M looks like:\n",
      "  (0, 1)\t0.07142857142857142\n",
      "  (0, 2)\t0.09090909090909091\n",
      "  (0, 3)\t0.08333333333333333\n",
      "  (0, 4)\t0.1\n",
      "  (0, 6)\t0.041666666666666664\n",
      "  (0, 8)\t0.14285714285714285\n",
      "  (0, 9)\t0.0625\n",
      "  (0, 12)\t0.2\n",
      "  (0, 13)\t0.1\n",
      "  (0, 14)\t0.05555555555555555\n",
      "  (0, 15)\t0.25\n",
      "  (0, 16)\t0.0625\n",
      "  (0, 19)\t0.1111111111111111\n",
      "  (0, 20)\t0.0625\n",
      "  (0, 21)\t0.05555555555555555\n",
      "  (0, 22)\t0.034482758620689655\n",
      "  (0, 23)\t0.0625\n",
      "  (0, 24)\t0.03333333333333333\n",
      "  (0, 25)\t0.07692307692307693\n",
      "  (0, 26)\t0.05263157894736842\n",
      "  (0, 27)\t0.025\n",
      "  (0, 28)\t0.06666666666666667\n",
      "  (0, 30)\t0.2\n",
      "  (0, 31)\t0.2\n",
      "  (0, 32)\t0.16666666666666666\n",
      "  :\t:\n",
      "  (875585, 875581)\t0.1111111111111111\n",
      "  (875586, 875581)\t0.1111111111111111\n",
      "  (875587, 875581)\t0.1111111111111111\n",
      "  (875588, 875581)\t0.1111111111111111\n",
      "  (875589, 875581)\t0.1111111111111111\n",
      "  (875590, 875581)\t0.1111111111111111\n",
      "  (875592, 875591)\t0.2\n",
      "  (875593, 875591)\t0.2\n",
      "  (875594, 875591)\t0.2\n",
      "  (875595, 875591)\t0.2\n",
      "  (875596, 875591)\t0.2\n",
      "  (875599, 875598)\t0.25\n",
      "  (875603, 875602)\t0.125\n",
      "  (875604, 875602)\t0.125\n",
      "  (875605, 875602)\t0.125\n",
      "  (875606, 875602)\t0.125\n",
      "  (875625, 875624)\t0.3333333333333333\n",
      "  (875655, 875654)\t0.25\n",
      "  (875669, 875668)\t0.25\n",
      "  (875671, 875670)\t0.5\n",
      "  (875677, 875676)\t0.16666666666666666\n",
      "  (875701, 875700)\t0.3333333333333333\n",
      "  (875702, 875700)\t0.3333333333333333\n",
      "  (875706, 875705)\t0.5\n",
      "  (875707, 875705)\t0.5\n"
     ]
    }
   ],
   "source": [
    "# number of nodes = 875712+1 because the ID ranging from 0 to 875712.\n",
    "n = 875712+1\n",
    "\n",
    "# create the sparse matrix M to store the information of out-links for each node.\n",
    "sparse_M = adjacency_matrix(web_array, outlinks, n)\n",
    "\n",
    "print(\"The sparse matrix M looks like:\")\n",
    "print(sparse_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The running time of implementing the power iteration in matrix form without considering the dead-ends and spider traps is:\n"
     ]
    }
   ],
   "source": [
    "# initialize the rank score r_0 = [1/N, ..., 1/N]^T\n",
    "r = np.full((n, 1), 1/n)\n",
    "\n",
    "print(\"The running time of implementing the power iteration in matrix form without considering the dead-ends and spider traps is:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3 s ± 57.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit power_iteration(sparse_M, r, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration, rank = power_iteration(sparse_M, r, 0.02)\n",
    "print(\"The number of iterations needed to stop is:\", str(iteration) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) The IDs and scores of the top-10 ranked nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the format of the final result\n",
    "def output_format(node_list):\n",
    "    data = np.empty((10,3), dtype=object)\n",
    "    # find the top 10 nodes with highest rank.\n",
    "    for i in range(10):\n",
    "        # rank starts at 1 so need to add 1 to the index i.\n",
    "        rank = int(i+1)\n",
    "        # find the node IDs with rank i+1\n",
    "        node_id = int(node_list[i][0])\n",
    "        # find the scores of the nodes\n",
    "        score = round(node_list[i][1],7)\n",
    "        # store the data in a list\n",
    "        data[i]=[rank,node_id,score]\n",
    "\n",
    "    # create a data frame to store all the data for top 10 nodes.\n",
    "    result = pd.DataFrame(data, columns = ['Rank','Node_ID','Score'])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an ID index array from 0 to 875712 to represent the ID.\n",
    "index = np.arange(n, dtype=int)\n",
    "index = np.transpose([index])\n",
    "# combine the nodes ID and their rank scores.\n",
    "rank_score = np.append(index,rank,axis=1)\n",
    "\n",
    "# order the nodes from highest rank score to lowest rank score.\n",
    "rank_score = rank_score.tolist() \n",
    "ordered_rank = sorted(rank_score, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"The IDs and scores for the top-10 ranked nodes are:\")\n",
    "display(output_format(ordered_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Extend the PageRank code to handle spider traps and dead-ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the updated power iteration function to handle spider traps and dead-ends.\n",
    "def update_power_iteration(M, r, beta, threshold):\n",
    "    # initialise the iteration number to be zero.\n",
    "    iteration = 0\n",
    "    \n",
    "    # initialise the difference between new_r and old_r to be infinite.\n",
    "    difference = float(\"inf\")\n",
    "    # initialise the old_r.\n",
    "    old_r = r\n",
    "    \n",
    "    # the iteration stops while difference < threshold.\n",
    "    while difference >= threshold:\n",
    "        # number of iteration adds 1.\n",
    "        iteration += 1\n",
    "        \n",
    "        # calculate new rank score for each nodes that have outlinks.\n",
    "        new_r = beta*M.dot(old_r)\n",
    "        # calculate sum of new rj\n",
    "        s = np.sum(new_r)\n",
    "        # update new rj with (1-s)/N\n",
    "        constant = (1-s)/n\n",
    "        new_r += constant\n",
    "        # the difference is the sum of the absolute values of the difference between new_r and old_r.\n",
    "        difference = np.sum(np.abs(np.subtract(new_r, old_r)))\n",
    "        # the new_r becomes old_r for next iteration.\n",
    "        old_r = new_r\n",
    "    \n",
    "    # return the final number of iterations and final rank score.\n",
    "    return iteration, old_r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code on the Google web data and report:\n",
    "\n",
    "#### (a) The running time and the number of iterations needed to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let beta = 0.9 by default.\n",
    "beta = 0.9\n",
    "\n",
    "print(\"The running time of implementing the power iteration in matrix form with considering the dead-ends and spider traps is:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit update_power_iteration(sparse_M, r, beta, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration, new_rank = update_power_iteration(sparse_M, r, beta, 0.02)\n",
    "print(\"The number of iterations needed to stop is:\", str(iteration) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (b) The IDs and scores of the top-10 ranked nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the IDs with their rank scores.\n",
    "new_rank_score = np.append(index,new_rank,axis=1)\n",
    "\n",
    "# order the nodes from highest rank score to lowest rank score.\n",
    "new_rank_score = new_rank_score.tolist() \n",
    "ordered_rank = sorted(new_rank_score, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"The IDs and scores for the top-10 ranked nodes are:\")\n",
    "display(output_format(ordered_rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) By varing the teleport probability $\\beta$ in [1, 0.9, 0.8, 0.7, 0.6], report the number of iterations needed to stop for each $beta$, and explain the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# varying the teleport probabilities.\n",
    "betas = [1, 0.9, 0.8, 0.7, 0.6]\n",
    "\n",
    "# for each beta, run the code and report the number of iterations needed to stop.\n",
    "for beta in betas:\n",
    "    iteration, new_rank = update_power_iteration(sparse_M, r, beta, 0.02)\n",
    "    print(\"The number of iterations needed to stop for beta =\", beta, \"is:\", str(iteration) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above runs the power iteration for each teleport probability $\\beta$ in [1, 0.9, 0.8, 0.7, 0.6]. From the output, it shows that the smaller the beta, the less number of iterations needed to stop. When the beta $\\beta = 1$, it means we only adjust the graph and link the dead ends to all other nodes with equal probability and compute the power iteration without any probability to randomly jump to another node. Thus, it needs the highest number of iterations to stop. However, with smaller beta, the larger the $(1-\\beta)$ which means the higher probability to randomly jump to another node and makes the $(1-\\beta ) [\\frac{1}{N}]_{NxN}$ larger and thus the rank scores are faster to converge. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implement the biased PageRank algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (a) Explain how you address the dead-end problem in biased PageRank.\n",
    "\n",
    "To address the dead-end problem in biased PageRank, I used the similar approach in Question 2. By definition, in biased PageRank, teleport only to nodes within a set S. The matrix formulation of biased PageRank is\n",
    "$$r = \\beta Mr + (1 - \\beta )\\frac{1}{|S|} e_S$$\n",
    "To address the dead-ends, the matrix $M$ needs to transit to a new matrix $M'$ where the dead ends are linked to nodes within the set S with equal probability. The euqation becomes\n",
    "$$r = \\beta M'r + (1 - \\beta )\\frac{1}{|S|} e_S$$\n",
    "$$= (\\beta Mr + \\beta \\frac{1}{|S|} e_S r_{deadend}) + (1-\\beta )\\frac{1}{|S|} e_S$$\n",
    "$$= \\beta Mr + \\beta \\frac{1}{|S|} e_S r_{deadend} + (1-\\beta )\\frac{1}{|S|} e_S$$\n",
    "$$r_j = \\beta \\sum_{i \\rightarrow j} \\frac{r_i}{d_i} + \\beta \\frac{1}{|S|} e_S r_{deadend} + (1-\\beta )\\frac{1}{|S|} e_S$$\n",
    "$$= \\beta \\sum_{i \\rightarrow j} \\frac{r_i}{d_i} + constant* e_S$$\n",
    "Therefore, firstly I calculate the new value of each node which is the same as before calculating $\\beta Mr$:\n",
    "$$ r_j^{new} = \\beta \\sum_{i \\rightarrow j} \\frac{r_i}{d_i}$$\n",
    "Then calculate the sum of new $r_j$, the sum is less than 1 because dead-ends leaked the scores:\n",
    "$$ SUM = \\sum_{j} r_j^{new} < 1$$\n",
    "The difference between 1 and SUM is the leaked scores, it should be equal to the constant times the number of nodes that dead-ends we supposed to linked to, that's the number of nodes in the teleport set.\n",
    "$$ 1-SUM = C*|S|$$\n",
    "By rearranging the equation, we get the equation for the constant.\n",
    "$$ C = \\frac{1-SUM}{|S|}$$\n",
    "Finally, update $r_j^{new}$ with constant C\n",
    "$$ r_j^{new} = r_j^{new} + \\frac{1-SUM}{|S|} e_S$$\n",
    "And I get the equation above is the method I use to address the dead-end problem in biased PageRank."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the biased PageRank algorithm and report:\n",
    "\n",
    "#### (b) The running time and the number of iterations needed to stop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_vector(set):\n",
    "    # initialise a vector with length n with value 0.\n",
    "    e = np.zeros(n)\n",
    "    vector = np.transpose([e])\n",
    "    # if node i is in the set S, the i-th value equals 1.\n",
    "    for node in set:\n",
    "        vector[node] = 1\n",
    "    return vector\n",
    "\n",
    "def biased_pagerank(M, r, beta, vector, threshold):\n",
    "    # initialise the iteration number to be zero.\n",
    "    iteration = 0\n",
    "    \n",
    "    # initialise the difference between new_r and old_r to be infinite.\n",
    "    difference = float(\"inf\")\n",
    "    # initialise the old_r.\n",
    "    old_r = r\n",
    "    \n",
    "    # the iteration stops while difference < threshold.\n",
    "    while difference >= threshold:\n",
    "        # number of iteration adds 1.\n",
    "        iteration += 1\n",
    "        \n",
    "        # calculate new rank score for each nodes that have outlinks.\n",
    "        new_r = beta*M.dot(old_r)\n",
    "        # calculate sum of new rj\n",
    "        s = np.sum(new_r)\n",
    "        # update new rj with (1-s)/|S|\n",
    "        constant = (1-s)/len(teleport_set)\n",
    "        new_r += constant*vector\n",
    "        # the difference is the sum of the absolute values of the difference between new_r and old_r.\n",
    "        difference = np.sum(np.abs(np.subtract(new_r, old_r)))\n",
    "        # the new_r becomes old_r for next iteration.\n",
    "        old_r = new_r\n",
    "    \n",
    "    # return the final number of iterations and final rank score.\n",
    "    return iteration, old_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the given teleport set of node IDs\n",
    "teleport_set = [768277, 296506, 77624, 596601, 234218, 222596, 1376, 783154]\n",
    "# construct the vector with the i-th value equals 1 if node i is in the teleport set S, otherwise 0.\n",
    "vector = e_vector(teleport_set)\n",
    "\n",
    "beta=0.9\n",
    "\n",
    "print(\"The running time of implementing the biased PageRank algorithm with considering the dead-ends is:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit biased_pagerank(sparse_M, r, beta, vector, 0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration, biased_rank = biased_pagerank(sparse_M, r, beta, vector, 0.02)\n",
    "print(\"The number of iterations needed to stop for the biased PageRank algorithm is:\", str(iteration) + \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (c) The IDs and scores of the top-10 tanked nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the IDs with their rank scores.\n",
    "biased_rank_score = np.append(index,biased_rank,axis=1)\n",
    "\n",
    "# order the nodes from highest rank score to lowest rank score.\n",
    "biased_rank_score = biased_rank_score.tolist() \n",
    "ordered_rank = sorted(biased_rank_score, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"The IDs and scores for the top-10 ranked nodes are:\")\n",
    "display(output_format(ordered_rank))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
